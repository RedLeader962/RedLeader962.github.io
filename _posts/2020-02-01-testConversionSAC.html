---
published: false
layout: distill
title: Soft Actor-Critic
description: TEST CONVERSION

authors:
  - name: Albert Einstein
    url: "https://en.wikipedia.org/wiki/Albert_Einstein"
    affiliations:
      name: IAS, Princeton
  - name: Boris Podolsky
    url: "https://en.wikipedia.org/wiki/Boris_Podolsky"
    affiliations:
      name: IAS, Princeton
  - name: Nathan Rosen
    url: "https://en.wikipedia.org/wiki/Nathan_Rosen"
    affiliations:
      name: IAS, Princeton

bibliography: 2019-11-01-a-reflexion-on-design-and-implementation.bib

_styles: >
    d-byline {
        padding: 1.5rem 0;
        padding-bottom: 0em;
        margin-bottom: 0em;
        min-height: 1.8em;
    }
    d-article {
        border-top: 0px solid rgba(0, 0, 0, 0.1);
        padding-top: 0rem;
        margin-top: 0rem;
    }
---

<h3 id="comment-on-notation">Comment on notation:</h3>

<!--<p>Since there are a lot of different notations across paper, I’ve decided to follow (for the most part) the convention established by Sutton &amp; Barto in their book Reinforcement Learning: An Introduction <span class="cite" data-citation-ids="Sutton1394"></span></p>-->

<div style="color: myGrayLabel">
<hr/></div>

<dl>
<dt><d-math>\displaystyle (\mathcal{S}, \mathcal{A}, T, \mathcal{R} )</d-math></dt>
<dd><p><strong>Markov decision process</strong><br/>with <d-math>\mathcal{S}</d-math> the state space, <d-math>\mathcal{A}</d-math> the action space, the transition fct <d-math>T</d-math> and a reward space <d-math>\mathcal{R}</d-math></p></dd>
<dt><d-math>\scriptstyle t \, \in \,  \interval{1}{\mathsf{T}}</d-math> </dt>
<dd><p>A <strong>time step</strong><br/>between the initiale state at <d-math>t=1</d-math> and the terminal state <d-math>t=\mathsf{T}</d-math></p></dd>
<dt><d-math>\scriptstyle \mathsf{T}</d-math></dt>

</dl>

<div style="color: myGrayLabel">
<hr/></div>
